# Springer CSV to BibTeX Converter

## Description
This Python script processes multiple `.csv` files in the same directory, extracts metadata from online articles (if a valid URL is provided), and generates a single `.bib` file in the BibTeX format. Since SpringerLink limits CSV exports to 1,000 records and does not provide a direct BibTeX export, this script helps merge multiple files while ensuring unique entries. The generated BibTeX file is enriched with metadata from the provided URLs, such as article title, abstract, pages, volume, issue, and more. However, if an article’s metadata is not fully retrievable from its webpage, some fields may remain incomplete. Additionally, excessive requests to SpringerLink may lead to temporary access restrictions.

---

## Requirements
1. Python 3.7 or higher.
2. The following Python libraries:
   - `requests`: To fetch article metadata from the URLs.
   - `beautifulsoup4`: To parse HTML and extract metadata.
   - `tqdm`: To display a progress bar during the process.

Install these libraries with:
```bash
pip install requests beautifulsoup4 tqdm
```
## How to Use

### Place CSV Files
Place all `.csv` files to be processed in the same directory as the script. 

The script will compare all entries across the provided CSV files, identify duplicates based on their DOI or a combination of title and authors, and ignore duplicate records to ensure only unique entries are processed.

### Run the Script
Execute the script using the command below. You will be prompted to provide the desired output BibTeX file name:
```bash
python springer_csv_to_bib.py
```
### BibTeX Output:
The script will generate a BibTeX file in the same directory with the name you specify.

### Example Console Output:

```bash
Processing the following CSV files:

file_1.csv
file_2.csv
Total unique entries: 150 Total duplicates found: 20

Enter the output file name (without extension, press Enter for default):
```

### What Happens During the Process:
The script will:
- Read all .csv files in the directory.
- Process each article's metadata, extracting additional information from its URL.
- Display a progress bar and the titles of the articles being processed.
- Save all entries into a single .bib file.

## CSV Input Format

The CSV files should have the following column headers:

- **Item Title**: The title of the article.
- **Publication Title**: The journal or conference name.
- **Journal Volume**: The volume number.
- **Journal Issue**: The issue number.
- **Item DOI**: The DOI of the article.
- **Authors**: The authors of the article (comma-separated).
- **Publication Year**: The year the article was published.
- **URL**: The link to the article.
- **Content Type**: The type of content (e.g., Article, Review).

## BibTeX Output Example

Here is an example of a BibTeX entry generated by the script:

```bibtex
@article{Deepak_2024,
  title={ A semantic ontology infused deep learning model for disaster tweet classification },
  volume={ 83 },
  DOI={ doi:10.1007/s11042-023-16840-6 },
  journal={ Multimedia Tools and Applications },
  author={ Karnati Sai Venkata GiriGerard Deepak },
  year={ 2024 },
  pages={ 62257-62285 },
  month={ 09 },
  abstract={ Twitter has emerged as a powerful Microblogging site in recent years. It has become one of the immediately reported platforms about any crisis in today’s world. During a crisis twitter is flooded with both informational and non-informational tweets. Informational tweets are the tweets which can help humanitarian response organizations or the victims to get useful information for better decision making This paper proposes a Semantic based Ontology Infused deep learning model for Informative tweet classification during natural disasters. The proposed model makes use of both text and image features present in a tweet during a classification, a Hierarchical ensemble of Vanilla and Bi-LSTM’s is used along with ontologies and external knowledge from OntoCollab for text classification, a dilated convolution-based residual neural network is used for image classification, and a meaningful statistical fusion is performed with the results obtained from text and image for tweet classification. The usage of both image and text features and contextual understanding made the model distinctive and achieved exceptional results. The proposed method has proven, after experiments, to achieve evaluation metrics better than the up-to-date existing methods; evaluated on seven different datasets and compared with eight other methods with an increase in Accuracy and decrease in FNR for seven distinguished datasets which resulted an highest F1 score of 98.416% on Sri Lanka Floods dataset. },
  issn={ 1573-7721 },
}

@article{Gu_2024,
  title={ Cognitive differences in product shape evaluation between real settings and virtual reality: case study of two-wheel electric vehicles },
  volume={ 28 },
  DOI={ doi:10.1007/s10055-024-01034-8 },
  journal={ Virtual Reality },
  author={ Zhengjie DuanJiajun ZhouFangzhou Gu },
  year={ 2024 },
  pages={ 1-14 },
  month={ 07 },
  abstract={ Product shape evaluation is an important part of new product development. In the shape design stage, design schemes are often presented through visual images. The presentation of visual images causes evaluators to form different cognitive experiences and evaluation results. In recent years, virtual reality (VR) technology has been widely used in the field of industrial design, enriching the presentation forms of design scheme images. Although VR technology has shown the potential to improve evaluators’ perception and cognitive experiences in product shape design, research comparing it with traditional methods remains relatively scattered. This study used two-wheel electric vehicles as an example to examine the difference in evaluators’ cognition of product shape in VR and a real setting (RS). First, we established a semantic scale comprising seven pairs of opposite adjectives to evaluate the shape scheme. Second, we built VR and RS evaluation environments using head-mounted displays and paper renderings, respectively. The participants evaluated the vehicle shape design in alternating viewing and underwent semi-structured interviews on cognitive experience. We analyzed the experimental and interview results based on three aspects of product shape cognition. The results demonstrated that volume cognition was significantly more accurate in VR environments. Furthermore, graphic cognition, particularly regarding shape details, differed partially between environments. VR provided a better sense of immersion and more variable viewing angles than RS. Treatment cognition did not exhibit significant differences between environments, as it depended on human experience rather than visualization. These findings suggest that VR tools are more suited for shaping design evaluations early. Selecting suitable visual presentation tools based on evaluators’ cognitive characteristics at different evaluation nodes to display design schemes is a practical, economical, and efficient strategy. },
  issn={ 1434-9957 },
}
```
## Key Fields in the Output

- **title**: The article's title.
- **volume**: The journal volume number.
- **DOI**: Digital Object Identifier of the article.
- **journal**: The name of the journal or publication.
- **author**: The authors of the article.
- **year**: The publication year.
- **pages**: The start and end pages of the article.
- **month**: The month of publication (if available).
- **abstract**: A summary or abstract of the article.
- **issn**: The ISSN of the journal.

## Notes

- The script automatically handles duplicate BibTeX keys by appending a letter (e.g., `Martin_2006a`, `Martin_2006b`).
- If any required metadata is missing or if a URL fails to fetch metadata, the script will gracefully skip that information.
